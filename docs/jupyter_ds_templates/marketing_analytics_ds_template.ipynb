{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120c2bb8",
   "metadata": {},
   "source": [
    "# marketing_analytics_ds_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3d2ec",
   "metadata": {},
   "source": [
    "## Sources\n",
    "* https://github.com/KelvinLam05/marketing_analytics/blob/main/marketing_analytics.ipynb\n",
    "* https://github.com/sundar911/marketing_analytics/blob/main/marketing_analytics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ab49b",
   "metadata": {},
   "source": [
    "## Algo\n",
    "* EDA:\n",
    "    * Data cleaning\n",
    "    * Stat Evals\n",
    "* General Questions:\n",
    "    * For any stat eval should something be normalized?\n",
    "    * Is a normal distribution required for the eval to be valid?\n",
    "    * Is the population homogenous except for the basis of comparison?\n",
    "    * Are seasons a factor?  Special Events?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c9cdd",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284fd66",
   "metadata": {},
   "source": [
    "### Outlier Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e136d",
   "metadata": {},
   "source": [
    "#### Describe DF\n",
    "```\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "#### Review outliers graphically\n",
    "#### Review outliers by drops, or imputation, or log transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74724f80",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "#### Check Nulls\n",
    "```\n",
    "df.isnull().sum()\n",
    "```\n",
    "### Clean Nulls\n",
    "```\n",
    "df[' Income '].fillna(df[' Income '].median(), inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b67c5",
   "metadata": {},
   "source": [
    "## Review Distributions\n",
    "### Example 1: .value_counts()\n",
    "```\n",
    "df['education'].value_counts()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5825eb2",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Example 1: Categorical Recode with apply(lambda\n",
    "```\n",
    "# Merge 'yolo', 'absurd', and 'alone' under 'single'\n",
    "df['marital_status'] = df['marital_status'].apply(lambda x: 'single' if str(x) in ['alone', 'yolo', 'absurd'] else str(x))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f13aad",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "#### Example 1:\n",
    "```\n",
    "one_hot_columns = list(bundled_pipeline.named_steps['preprocessor'].named_transformers_['categorical'].named_steps['one_hot_encoder'].get_feature_names_out(input_features = categorical_columns))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079431f7",
   "metadata": {},
   "source": [
    "## Review Correlation\n",
    "### Example 1: Using ColumnTransformer, SimpleImputer, associations\n",
    "```\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from dython.nominal import associations\n",
    "\n",
    "transformer = ColumnTransformer(transformers = [('simple_imputer', SimpleImputer(strategy = 'median'), ['income'])], remainder = 'passthrough')\n",
    "\n",
    "complete_correlation = associations(X_tr, figsize = (32, 16))\n",
    "\n",
    "The rule of thumb is that .8 is too collinear.\n",
    "There is a process for automatically dropping over-correlated variables, but don't remember how that's done.\n",
    "```\n",
    "### Example 2: Seaborn Heatmap\n",
    "```\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df_income_marketing.corr('spearman'), center=0, annot=True);\n",
    "```\n",
    "\n",
    "### Chi Squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f898edd",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "### Example 1: Using ELI5\n",
    "```\n",
    "import eli5\n",
    "eli5.explain_weights(bundled_pipeline.named_steps['model'], top = 50, feature_names = numeric_features_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e678ed97",
   "metadata": {},
   "source": [
    "### Feature Importance Using Shapely Values\n",
    "```\n",
    "import shap\n",
    "\n",
    "# calculate shap values \n",
    "ex = shap.Explainer(model, x_train)\n",
    "shap_values = ex(x_test)\n",
    "\n",
    "# plot\n",
    "plt.title('SHAP summary for NumStorePurchases', size=16)\n",
    "shap.plots.beeswarm(shap_values, max_display=5);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14867f81",
   "metadata": {},
   "source": [
    "## Eval Key X-Y Relationships from Correlation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47888c2e",
   "metadata": {},
   "source": [
    "## Evaluate Variance\n",
    "### Get Equal Sized Samples\n",
    "```\n",
    "below_average = below_average.sample(703)\n",
    "```\n",
    "### Use Levene Test:\n",
    "```\n",
    "import scipy.stats as stats\n",
    "stats.levene(above_average['numstorepurchases'], below_average['numstorepurchases'])\n",
    "LeveneResult(statistic=15.638759392178962, pvalue=8.048902576767652e-05)\n",
    "The resulting p-value is less than 0.05, we fail to reject the null hypothesis of the variances being equal.\n",
    "```\n",
    "### Evaluate Residual Distribution:\n",
    "* Normality\n",
    "```\n",
    "Check residual distribution using Kolmogorov-Smirnov test.\n",
    "diff = scale(np.array(above_average['numstorepurchases']) - np.array(below_average['numstorepurchases']))\n",
    "from scipy.stats import kstest\n",
    "kstest(diff, 'norm')\n",
    "\n",
    "KstestResult(statistic=0.0711000050880169, pvalue=0.0015527924807426162)\n",
    "\n",
    "As the p-value obtained from the Kolmogorov-Smirnov test is significant (p < 0.05), we conclude that the residuals are not normally distributed. Therefore, Mann-Whitney U test is more appropriate for analyzing two samples.\n",
    "```\n",
    "\n",
    "### Performan Mann-Whitney Test\n",
    "```\n",
    "Perform one-sided Mann-Whitney U test,\n",
    "stats.mannwhitneyu(x = above_average['numstorepurchases'], y = below_average['numstorepurchases'], alternative = 'greater')\n",
    "MannwhitneyuResult(statistic=378065.5, pvalue=2.3990673662361752e-67)\n",
    "As the p-value obtained from the Mann-Whitney U test is significant (p < 0.05), we can conclude that store purchases of people who spend more on gold is greater than store purchases of people who spend less on gold. Thus, the supervisor's claim is justified.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f274e",
   "metadata": {},
   "source": [
    "### MANOVA\n",
    "#### Source: \n",
    "```https://github.com/sundar911/marketing_analytics/blob/main/marketing_analytics.ipynb\n",
    "```\n",
    "#### Imports:\n",
    "```\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "```\n",
    "#### Prep with Normalization\n",
    "```\n",
    "df_scaled = pd.DataFrame(columns=['Country', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntSweetProducts', 'MntFishProducts','MntGoldProds'])\n",
    "\n",
    "for i in ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntSweetProducts', 'MntFishProducts','MntGoldProds']:\n",
    "  final = []\n",
    "\n",
    "  for j in ['GER', 'IND', 'SP', 'US', 'CA', 'SA', 'AUS']:\n",
    "    scaled = scaler.fit_transform( np.asarray (df[df.Country==j][i]).reshape(-1,1) )\n",
    "\n",
    "    for k in scaled:\n",
    "      final.append(k[0])\n",
    "    \n",
    "  df_scaled[i] = final\n",
    "```\n",
    "#### Having Performed Levine's Test\n",
    "```\n",
    "for i in ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntSweetProducts', 'MntFishProducts','MntGoldProds']:\n",
    "  sp = df_scaled.query('Country == \"SP\"')[i]\n",
    "  us = df_scaled.query('Country == \"CA\"')[i]\n",
    "  ca = df_scaled.query('Country == \"US\"')[i]\n",
    "  aus = df_scaled.query('Country == \"AUS\"')[i]\n",
    "  ger = df_scaled.query('Country == \"GER\"')[i]\n",
    "  ind = df_scaled.query('Country == \"IND\"')[i]\n",
    "  sa = df_scaled.query('Country == \"SA\"')[i]\n",
    "\n",
    "  # Bartlett's test in Python with SciPy:\n",
    "  stat, p = stats.levene(sp, us, ca, aus, ger, ind, sa)\n",
    "\n",
    "  # Get the results:\n",
    "  print(stat, p)\n",
    "  \n",
    "Levene's indicates that the variance among each product sales across countries is not significantly different which is basically a statistical nod for going ahead with the MANOVA\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9b4f2",
   "metadata": {},
   "source": [
    "## Common Web Analytic Metric Calcs\n",
    "### CPC\n",
    "```\n",
    "def average_calculation(df):\n",
    "    \n",
    "    # Cost Per Click \n",
    "    df['Cost Per Click'] = df['Facebook Cost']/df['Facebook Clicks']\n",
    "\n",
    "    # Click Through Rate\n",
    "    df['Click Through Rate'] = df['Facebook Clicks']/df['Facebook Impressions']*100\n",
    "\n",
    "    # Conversion Ratio\n",
    "    df['Converstion Ratio'] = df['Facebook Conversions']/df['Facebook Clicks']*100\n",
    "    \n",
    "    return df\n",
    "```\n",
    "### Cost Per Lead\n",
    "\n",
    "```\n",
    "def cost_per_lead_calc(amount,data):\n",
    "    \n",
    "    # Empty Dictionary\n",
    "    cost_lead = dict()\n",
    "    \n",
    "    # Amount\n",
    "    cost_lead['Budget Assumption'] = amount\n",
    "    \n",
    "    # Average CPC\n",
    "    cost_lead['Average CPC'] = round(data['Cost Per Click'],2)\n",
    "    \n",
    "    # Average Total Clicks \n",
    "    cost_lead['Average Total Clicks'] = round(amount/data['Cost Per Click'],0)\n",
    "    \n",
    "    # Average Lead Conversion \n",
    "    cost_lead['Average Lead CNV'] = round(data['Converstion Ratio'],2)\n",
    "    \n",
    "    # Average Total Leads\n",
    "    cost_lead['Average Total Leads'] = round(cost_lead['Average Total Clicks']*data['Converstion Ratio']/100,0)\n",
    "    \n",
    "    # Cost Per Lead \n",
    "    cost_lead['Cost Per Lead'] = round(amount/cost_lead['Average Total Leads'],2)\n",
    "    \n",
    "    # Dataframe Formation\n",
    "    df = pd.DataFrame(cost_lead)\n",
    "    \n",
    "    return df.T\n",
    "```\n",
    "### CLV/LTV\n",
    "```\n",
    "# Customer Total Lifetime Value\n",
    "\n",
    "def cust_life_value(lead_overall,margin,discount,retention_rate):\n",
    "    \n",
    "    # Empty Dict\n",
    "    customer_liftime_table = dict()\n",
    "    \n",
    "    # Average Total Purchase Cost\n",
    "    atpc = round(lead_overall['Average Total Purchase'],2)\n",
    "    customer_liftime_table['Average Total Purchase Cost'] = atpc\n",
    "    \n",
    "    # Margin (Assumpt.)\n",
    "    customer_liftime_table['Margin (Assumpt.)'] = margin\n",
    "    \n",
    "    # Average Gross profit\n",
    "    agp = round(margin/100*atpc,2)\n",
    "    customer_liftime_table['Average Gross Profit'] = agp\n",
    "    \n",
    "    # Customer Retention Rate\n",
    "    crt = round(retention_rate/100,2)\n",
    "    customer_liftime_table['Customer Retention Rate'] = retention_rate\n",
    "    \n",
    "    # Average Discount rate\n",
    "    dis = round(discount/100,2)\n",
    "    customer_liftime_table['Average Discount Rate'] = discount\n",
    "    \n",
    "    # Average CLV\n",
    "    clv = round(agp*(crt/(1+dis-crt)),2)\n",
    "    customer_liftime_table['Average CLV'] = clv\n",
    "    \n",
    "    # Average Cust Acq Cost\n",
    "    acqc = round(lead_overall['Customer Acquisition Cost'],2)\n",
    "    customer_liftime_table['Average Cust Acq Cost'] = acqc\n",
    "    \n",
    "    # Average CLV Net\n",
    "    aclv_net = round(clv-acqc,2)\n",
    "    customer_liftime_table['Average CLV Net'] = aclv_net\n",
    "    \n",
    "    return pd.DataFrame(customer_liftime_table)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
